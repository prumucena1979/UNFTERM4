{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DAMO-630-29 Assignment 01",
   "id": "6e2240ab32a6e0ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer\n",
    "from sdmetrics.reports.single_table import QualityReport, DiagnosticReport"
   ],
   "id": "6d3a3284bc7b44c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BUSINESS CHALLENGE #01",
   "id": "98dd376483fb7d38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TASK I - Exploratory Data Analisis",
   "id": "18ce40fcce8e19af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The EDA offers an initial overview of the dataset by inspecting its structure, detecting missing values or outliers, and applying descriptive statistics with visualizations. These insights provide the foundation for subsequent synthetic data generation and evaluation.",
   "id": "b406cbe8bf4da914"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.1. load dataset\n",
    "df = pd.read_csv(\"Datasets\\HealthInsurance.csv\")  # adjust file name as needed"
   ],
   "id": "ee00ac61e09c056d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.2. Shape\n",
    "print(\"Shape:\", df.shape)"
   ],
   "id": "fa048ae0b60f5cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.3. Preview\n",
    "display(df.head())"
   ],
   "id": "f75f5f50056ce7f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.4. Info\n",
    "df.info()"
   ],
   "id": "277a5209e603e514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.5. Descriptive statistics\n",
    "display(df.describe())"
   ],
   "id": "8b7b17d77ea8c1b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.6. Missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 1.7. Distribution plots (example numeric columns)\n",
    "for col in df.select_dtypes(include=np.number).columns[:3]:\n",
    "    plt.hist(df[col].dropna(), bins=30)\n",
    "    plt.title(f\"Distribution: {col}\")\n",
    "    plt.show()"
   ],
   "id": "ae2222606906543b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Task II — Baseline Synthetic Data",
   "id": "379d9c0d8d705b92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.1 Random noise baseline\n",
    "synthetic_baseline = pd.DataFrame(\n",
    "    np.random.randn(df.shape[0], df.shape[1]),\n",
    "    columns=df.columns\n",
    ")\n",
    "display(synthetic_baseline.head())"
   ],
   "id": "81e59090984128fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Task III — Advanced Synthetic Data (SDV)",
   "id": "b23ec337b8fbcc1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3.1 Infer table metadata (types, constraints, relations)\n",
    "metadata = Metadata.detect_from_dataframe(data=df, table_name=\"my_table\")"
   ],
   "id": "b85f14455dabf55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3.2 GaussianCopula\n",
    "gc = GaussianCopulaSynthesizer(metadata)\n",
    "gc.fit(df)\n",
    "synthetic_gc = gc.sample(num_rows=len(df))\n",
    "display(synthetic_gc.head())"
   ],
   "id": "495d0099240801bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3.3 CTGAN\n",
    "ctgan = CTGANSynthesizer(metadata, epochs=200, batch_size=100, verbose=True)\n",
    "ctgan.fit(df)\n",
    "synthetic_ctgan = ctgan.sample(num_rows=len(df))\n",
    "display(synthetic_ctgan.head())"
   ],
   "id": "5275938f8c308c5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Task IV — Evaluation",
   "id": "7127908b2020ea31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert metadata for sdmetrics (single table)",
   "id": "deba1594641e8aa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert metadata for sdmetrics (single table)\n",
    "_meta_dict = metadata.to_dict()\n",
    "if \"tables\" in _meta_dict:\n",
    "    _table_name = next(iter(_meta_dict[\"tables\"].keys()))\n",
    "    single_table_meta = _meta_dict[\"tables\"][_table_name]\n",
    "else:\n",
    "    single_table_meta = _meta_dict"
   ],
   "id": "a6c5fe92d237003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4.1 Quality and Diagnostics\n",
    "qr_gc = QualityReport(); qr_gc.generate(df, synthetic_gc, single_table_meta)\n",
    "qr_ct = QualityReport(); qr_ct.generate(df, synthetic_ctgan, single_table_meta)\n",
    "\n",
    "print(\"Quality — GC:\", qr_gc.get_score())\n",
    "print(\"Quality — CTGAN:\", qr_ct.get_score())\n",
    "\n",
    "dr_gc = DiagnosticReport(); dr_gc.generate(df, synthetic_gc, single_table_meta)\n",
    "dr_ct = DiagnosticReport(); dr_ct.generate(df, synthetic_ctgan, single_table_meta)"
   ],
   "id": "c68b4698d7883e51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4.2 Correlation Preservation\n",
    "def corr_rmse(a, b):\n",
    "    cols = a.select_dtypes(include=np.number).columns.intersection(\n",
    "        b.select_dtypes(include=np.number).columns\n",
    "    )\n",
    "    if len(cols) < 2:\n",
    "        return np.nan\n",
    "    ca, cb = a[cols].corr(), b[cols].corr()\n",
    "    mask = np.triu(np.ones_like(ca, dtype=bool), k=1)\n",
    "    diff = (ca - cb).where(mask)\n",
    "    vals = diff.values[~np.isnan(diff.values)]\n",
    "    return np.sqrt(np.mean(vals**2)) if len(vals) else np.nan\n",
    "\n",
    "print(\"Correlation RMSE — GC:\", corr_rmse(df, synthetic_gc))\n",
    "print(\"Correlation RMSE — CTGAN:\", corr_rmse(df, synthetic_ctgan))"
   ],
   "id": "e2d0adea4fa68a92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4.3 Utility — TSTR (Train on Synthetic, Test on Real)\n",
    "def tstr_classification(real_df, synth_df, target):\n",
    "    Xs, ys = synth_df.drop(columns=[target]), synth_df[target]\n",
    "    Xr, yr = real_df.drop(columns=[target]), real_df[target]\n",
    "    Xs = Xs.select_dtypes(include=np.number).fillna(Xs.median(numeric_only=True))\n",
    "    Xr = Xr.select_dtypes(include=np.number).fillna(Xr.median(numeric_only=True))\n",
    "    clf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "    clf.fit(Xs, ys)\n",
    "    pred = clf.predict(Xr)\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(yr, pred),\n",
    "        \"f1_macro\": f1_score(yr, pred, average=\"macro\")\n",
    "    }\n",
    "    if len(clf.classes_) == 2:\n",
    "        out[\"roc_auc\"] = roc_auc_score(yr, clf.predict_proba(Xr)[:, 1])\n",
    "    return out\n",
    "\n",
    "def tstr_regression(real_df, synth_df, target):\n",
    "    Xs, ys = synth_df.drop(columns=[target]), synth_df[target]\n",
    "    Xr, yr = real_df.drop(columns=[target]), real_df[target]\n",
    "    Xs = Xs.select_dtypes(include=np.number).fillna(Xs.median(numeric_only=True))\n",
    "    Xr = Xr.select_dtypes(include=np.number).fillna(Xr.median(numeric_only=True))\n",
    "    reg = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "    reg.fit(Xs, ys)\n",
    "    pred = reg.predict(Xr)\n",
    "    return {\"r2\": r2_score(yr, pred), \"mae\": mean_absolute_error(yr, pred)}\n",
    "\n",
    "# Example (uncomment and set target column)\n",
    "# print(tstr_classification(df, synthetic_gc, \"your_target\"))\n",
    "# print(tstr_classification(df, synthetic_ctgan, \"your_target\"))"
   ],
   "id": "9058a0079984a087",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4.4 Privacy — exact duplicates\n",
    "def exact_dup_rate(real_df, synth_df):\n",
    "    r = real_df.astype(str).agg(\"|\".join, axis=1)\n",
    "    s = synth_df.astype(str).agg(\"|\".join, axis=1)\n",
    "    return len(set(r) & set(s)) / max(1, len(s))\n",
    "\n",
    "print(\"Duplication rate — GC:\", exact_dup_rate(df, synthetic_gc))\n",
    "print(\"Duplication rate — CTGAN:\", exact_dup_rate(df, synthetic_ctgan))"
   ],
   "id": "7b1267ea70b2094d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BUSINESS CHALLENGE #02",
   "id": "4a0bfb488a223ba1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preparation",
   "id": "a71f849079bc9c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os, subprocess, sys\n",
    "\n",
    "# 1) Point to your Temurin JDK 17 install (adjust if your folder name differs)\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Eclipse Adoptium\\jdk-17\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + r\"\\bin;\" + os.environ[\"PATH\"]\n",
    "\n",
    "# 2) Quick check: Java visible to this kernel?\n",
    "try:\n",
    "    out = subprocess.check_output([\"java\", \"-version\"], stderr=subprocess.STDOUT)\n",
    "    print(out.decode(\"utf-8\"))\n",
    "except Exception as e:\n",
    "    print(\"Java not visible to the kernel:\", e)\n",
    "\n",
    "# 3) (Optional) Confirm PySpark version\n",
    "try:\n",
    "    import pyspark\n",
    "    print(\"PySpark:\", pyspark.__version__)\n",
    "except Exception as e:\n",
    "    print(\"PySpark not importable:\", e, \"\\nTip: pip install -U 'pyspark>=3.5,<4.0'\")\n"
   ],
   "id": "fe5790f6096c8728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create SparkSession",
   "id": "3d3787af1341790d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# BC2 — Setup (PySpark)\n",
    "# ========================="
   ],
   "id": "a3ecd59bf94fe1b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load parquet file - dataset",
   "id": "ecb6eefe4838fba5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TAXI_PATH = \"Datasets\\yellow_tripdata_2025-03.parquet\"\n",
    "df = spark.read.parquet(TAXI_PATH)\n",
    "\n",
    "print(\"Row count:\", df.count())\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ],
   "id": "3deacdf2daf97398",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
